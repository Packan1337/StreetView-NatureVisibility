{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1aujgNKvVrz",
        "outputId": "f97f058b-3269-47a5-9ff1-fbfe4418bdf1"
      },
      "outputs": [],
      "source": [
        "# Use this block of code when working on Google Colab in order to save the files in Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"drive/MyDrive/Thesis/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T92Iwq3WvaG4",
        "outputId": "5d1df63c-32d7-4993-f984-126418e3cc90"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install geopandas\n",
        "%pip install torch==1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wqb2jsMQvVMK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f_/xfklpqfj6kjg8yr6l1byph0h0000gn/T/ipykernel_4678/1948481378.py:8: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
            "\n",
            "import os\n",
            "os.environ['USE_PYGEOS'] = '0'\n",
            "import geopandas\n",
            "\n",
            "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
            "  import geopandas as gpd\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "import geopandas as gpd\n",
        "import json\n",
        "import os\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L3lAX46-vVMN"
      },
      "outputs": [],
      "source": [
        "# color palette to map each class to a RGB value\n",
        "\n",
        "color_palette = [\n",
        "    [128, 64, 128],  # 0: road - maroon\n",
        "    [244, 35, 232],  # 1: sidewalk - pink\n",
        "    [70, 70, 70],  # 2: building - dark gray\n",
        "    [102, 102, 156],  # 3: wall - purple\n",
        "    [190, 153, 153],  # 4: fence - light brown\n",
        "    [153, 153, 153],  # 5: pole - gray\n",
        "    [250, 170, 30],  # 6: traffic light - orange\n",
        "    [220, 220, 0],  # 7: traffic sign - yellow\n",
        "    [107, 142, 35],  # 8: vegetation - dark green\n",
        "    [152, 251, 152],  # 9: terrain - light green\n",
        "    [70, 130, 180],  # 10: sky - blue\n",
        "    [220, 20, 60],  # 11: person - red\n",
        "    [255, 0, 0],  # 12: rider - bright red\n",
        "    [0, 0, 142],  # 13: car - dark blue\n",
        "    [0, 0, 70],  # 14: truck - navy blue\n",
        "    [0, 60, 100],  # 15: bus - dark teal\n",
        "    [0, 80, 100],  # 16: train - dark green\n",
        "    [0, 0, 230],  # 17: motorcycle - blue\n",
        "    [119, 11, 32]  # 18: bicycle - dark red\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WZBFlPrRPjiT"
      },
      "outputs": [],
      "source": [
        "def prepare_folders(path, city):\n",
        "  # Create the directories to store the images, segments and pickles if they do not exist\n",
        "  dir_path = os.path.join(path, \"results\", city, \"images\")\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  \n",
        "  dir_path = os.path.join(path, \"results\", city, \"segments\")\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "  \n",
        "  dir_path = os.path.join(path, \"results\", city, \"pickles\")\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "\n",
        "  dir_path = os.path.join(path, \"results\", city, \"roads\")\n",
        "  if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "reHOXOvXvVMN"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
        "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
        "\n",
        "    return processor, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RN5qCDiKvVMO"
      },
      "outputs": [],
      "source": [
        "def segment_images(image_path, image_id, is_panoramic, processor, model, city, path=\"\"):\n",
        "    image = Image.open(requests.get(image_path, stream=True).raw)\n",
        "\n",
        "    # If the image is panormic, we need to cut the band in the bottom of it\n",
        "    if is_panoramic:\n",
        "        # Get the size of the image\n",
        "        width, height = image.size\n",
        "\n",
        "        # Crop the bottom 10% of the image\n",
        "        bottom_crop = int(height * 0.2)\n",
        "        image = image.crop((0, 0, width, height - bottom_crop))\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # forward pass\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    # you can pass them to processor for postprocessing\n",
        "    seg = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
        "    \n",
        "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
        "    palette = np.array(color_palette)\n",
        "    for label, color in enumerate(palette):\n",
        "        color_seg[seg == label, :] = color\n",
        "\n",
        "    # Show image + mask\n",
        "    img = np.array(image) * 0.4 + color_seg * 0.6\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    # Save original image\n",
        "    dir_path = os.path.join(path, \"results\", city, \"images\")\n",
        "    img_path = os.path.join(dir_path, \"{}.jpg\".format(image_id))\n",
        "    image.save(img_path)\n",
        "    \n",
        "    # Convert numpy array to PIL Image and save masked image\n",
        "    pil_img = Image.fromarray(img)\n",
        "    dir_path = os.path.join(path, \"results\", city, \"segments\")\n",
        "    img_path = os.path.join(dir_path, \"{}.png\".format(image_id))\n",
        "    pil_img.save(img_path)\n",
        "\n",
        "    # Save segmentation array as a pickle file\n",
        "    dir_path = os.path.join(path, \"results\", city, \"pickles\")\n",
        "    pickle_path = os.path.join(dir_path, \"{}.pkl\".format(image_id))\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(seg, f)\n",
        "    \n",
        "    return pickle_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D4RqT4zTvVMP"
      },
      "outputs": [],
      "source": [
        "# Based on Matthew Danish code (https://github.com/mrd/vsvi_filter/tree/master)\n",
        "def run_length_encoding(in_array):\n",
        "    image_array = np.asarray(in_array)\n",
        "    length = len(image_array)\n",
        "    if length == 0: \n",
        "        return (None, None, None)\n",
        "    else:\n",
        "        pairwise_unequal = image_array[1:] != image_array[:-1]\n",
        "        change_points = np.append(np.where(pairwise_unequal), length - 1)   # must include last element posi\n",
        "        run_lengths = np.diff(np.append(-1, change_points))       # run lengths\n",
        "        positions = np.cumsum(np.append(0, run_lengths))[:-1] # positions\n",
        "        return(run_lengths, positions, image_array[change_points])\n",
        "\n",
        "def get_road_pixels_per_column(prediction):\n",
        "    road_pixels = prediction == 0.0 # The label for the roads is 0\n",
        "    road_pixels_per_col = np.zeros(road_pixels.shape[1])\n",
        "    for i in range(road_pixels.shape[1]):\n",
        "        run_lengths, positions, values = run_length_encoding(road_pixels[:,i])\n",
        "        road_pixels_per_col[i] = run_lengths[values.nonzero()].max(initial=0)\n",
        "    return road_pixels_per_col\n",
        "\n",
        "def get_road_centres(prediction, distance=2000, prominence=100):\n",
        "    road_pixels_per_col = get_road_pixels_per_column(prediction)\n",
        "    return find_peaks(road_pixels_per_col, distance=distance, prominence=prominence)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hwhQRWsYvVMQ"
      },
      "outputs": [],
      "source": [
        "def find_road_center(filename, image_id, city, path):\n",
        "    predict = np.load(filename, allow_pickle=True)\n",
        "\n",
        "    distance = int(2000 * predict.shape[1] // 5760)\n",
        "    prominence = int(100 * predict.shape[0] // 2880)\n",
        "\n",
        "    centres = get_road_centres(predict, distance=distance, prominence=prominence)\n",
        "    \n",
        "    if centres.size > 0:\n",
        "      palette_bytes = bytes([c for color in color_palette for c in color]) # concatenate rgb\n",
        "      predict_np = predict.numpy()\n",
        "      mask = Image.fromarray(predict_np.astype('uint8')).convert('P')\n",
        "      mask.putpalette(palette_bytes)\n",
        "      mask.load()\n",
        "      \n",
        "      draw = ImageDraw.Draw(mask)\n",
        "      \n",
        "      for centre in centres:\n",
        "        draw.line((centre, 0, centre, mask.size[1]), width=4, fill=(0,255,0))\n",
        "    \n",
        "      path_to_file=\"{}results/{}/roads/{}.png\".format(path, city, image_id)\n",
        "      mask.save(path_to_file)\n",
        "\n",
        "      return True\n",
        "    else:\n",
        "      return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vqe9dQ1XvVMO"
      },
      "outputs": [],
      "source": [
        "# Download images\n",
        "def download_image(image_metadata, city, access_token, processor, model, path=\"\"):\n",
        "    header = {'Authorization': 'OAuth {}'.format(access_token)}\n",
        "\n",
        "    image_id = image_metadata[\"properties\"][\"id\"]\n",
        "    is_panoramic = image_metadata[\"properties\"][\"is_pano\"]\n",
        "    \n",
        "    url = 'https://graph.mapillary.com/{}?fields=thumb_original_url'.format(image_id)\n",
        "    response = requests.get(url, headers=header)\n",
        "    data = response.json()\n",
        "    image_url = data[\"thumb_original_url\"]\n",
        "\n",
        "    # Image segmentation\n",
        "    pickle_path = segment_images(image_url, image_id, is_panoramic, processor, model, city)\n",
        "    \n",
        "    # Find roads to determine if the image is suitable for the analysis or not AND crop the panoramic images\n",
        "    usable = find_road_center(pickle_path, image_id, city, path)\n",
        "\n",
        "    return [image_id, usable]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Yi70VyJLvVMP"
      },
      "outputs": [],
      "source": [
        "def download_images_for_points(city, access_token, path=\"\"):\n",
        "    path_to_file=\"{}results/{}/data/points_with_features.gpkg\".format(path, city)\n",
        "    gdf_features = gpd.read_file(path_to_file)\n",
        "\n",
        "    # Load cache\n",
        "    cache_file = os.path.join(path, \"results\", city, \"data\", \"cache.txt\")\n",
        "    if os.path.exists(cache_file):\n",
        "        with open(cache_file, \"r\") as f:\n",
        "            cache = set([line.strip() for line in f])\n",
        "    else:\n",
        "        cache = set()\n",
        "\n",
        "    prepare_folders(path, city)\n",
        "    processor, model = get_models()\n",
        "    images_results = []\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "  \n",
        "        for feature in gdf_features[\"feature\"]:\n",
        "            feature = json.loads(feature)\n",
        "            image_id = feature[\"properties\"][\"id\"]\n",
        "            \n",
        "            if image_id not in cache:\n",
        "                futures.append(executor.submit(download_image, feature, city, access_token, processor, model, path))\n",
        " \n",
        "        for future in (pbar:= tqdm(futures, total=len(futures))):\n",
        "            pbar.set_description(f\"Downloading images\")\n",
        "            image_result = future.result()\n",
        "            images_results.append(image_result)\n",
        "            cache.add(image_result[0])\n",
        "    \n",
        "    # Save cache\n",
        "    with open(cache_file, \"w\") as f:\n",
        "        for image_id in cache:\n",
        "            f.write(\"{}\\n\".format(image_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hV_HAPW1vVMQ"
      },
      "outputs": [],
      "source": [
        "# Get the roadnetwork of a specific city using OpenStreetMap data\n",
        "city = \"Kampala, Uganda\"\n",
        "\n",
        "# Set access token for mapillary\n",
        "access_token = \"MLY|6267906093323631|fba37c53726a386c951323ee5b9874bf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFEx3Hp0vVMQ",
        "outputId": "e1589c07-7ce7-4217-c539-63922169f1a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
            "Downloading images:   0%|          | 101/49480 [07:34<61:43:05,  4.50s/it]\n"
          ]
        }
      ],
      "source": [
        "download_images_for_points(city, access_token, path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ssml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
