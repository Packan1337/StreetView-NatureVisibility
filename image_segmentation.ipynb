{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color palette to map each class to a RGB value\n",
    "\"\"\"{0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence', 5: 'pole', 6: 'traffic light', 7: 'traffic sign', 8: 'vegetation', 9: 'terrain', 10: 'sky', 11: 'person', 12: 'rider', 13: 'car', 14: 'truck', 15: 'bus', 16: 'train', 17: 'motorcycle', 18: 'bicycle'}\"\"\"\n",
    "color_palette = [\n",
    "    [128, 64, 128],  # road - maroon\n",
    "    [244, 35, 232],  # sidewalk - pink\n",
    "    [70, 70, 70],  # building - dark gray\n",
    "    [102, 102, 156],  # wall - purple\n",
    "    [190, 153, 153],  # fence - light brown\n",
    "    [153, 153, 153],  # pole - gray\n",
    "    [250, 170, 30],  # traffic light - orange\n",
    "    [220, 220, 0],  # traffic sign - yellow\n",
    "    [107, 142, 35],  # vegetation - dark green\n",
    "    [152, 251, 152],  # terrain - light green\n",
    "    [70, 130, 180],  # sky - blue\n",
    "    [220, 20, 60],  # person - red\n",
    "    [255, 0, 0],  # rider - bright red\n",
    "    [0, 0, 142],  # car - dark blue\n",
    "    [0, 0, 70],  # truck - navy blue\n",
    "    [0, 60, 100],  # bus - dark teal\n",
    "    [0, 80, 100],  # train - dark green\n",
    "    [0, 0, 230],  # motorcycle - blue\n",
    "    [119, 11, 32]  # bicycle - dark red\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "\n",
    "    return processor, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_images(image_path, image_id, processor, model, city, path=\"\"):\n",
    "    image = Image.open(requests.get(image_path, stream=True).raw)\n",
    "\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # you can pass them to processor for postprocessing\n",
    "    seg = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    \n",
    "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "    palette = np.array(color_palette)\n",
    "    for label, color in enumerate(palette):\n",
    "        color_seg[seg == label, :] = color\n",
    "\n",
    "    # Show image + mask\n",
    "    img = np.array(image) * 0.4 + color_seg * 0.6\n",
    "    img = img.astype(np.uint8)\n",
    "\n",
    "    # Save original image\n",
    "    dir_path = os.path.join(path, \"images\", city)\n",
    "    img_path = os.path.join(dir_path, \"{}.jpg\".format(image_id))\n",
    "    image.save(img_path)\n",
    "    \n",
    "    # Convert numpy array to PIL Image and save masked image\n",
    "    pil_img = Image.fromarray(img)\n",
    "    dir_path = os.path.join(path, \"segments\", city)\n",
    "    img_path = os.path.join(dir_path, \"{}.png\".format(image_id))\n",
    "    pil_img.save(img_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images in parallel\n",
    "def download_image(image_metadata, city, access_token, processor, model, path=\"\"):\n",
    "    header = {'Authorization': 'OAuth {}'.format(access_token)}\n",
    "\n",
    "    image_id = image_metadata[\"properties\"][\"id\"]\n",
    "    \n",
    "    url = 'https://graph.mapillary.com/{}?fields=thumb_1024_url'.format(image_id)\n",
    "    response = requests.get(url, headers=header)\n",
    "    data = response.json()\n",
    "    image_url = data[\"thumb_1024_url\"]\n",
    "\n",
    "    segment_images(image_url, image_id, processor, model, city)\n",
    "\n",
    "    return image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images_for_points(city, access_token, path=\"\"):\n",
    "    path_to_file=\"{}data/{}/{} points with features.gpkg\".format(path, city, city)\n",
    "    gdf_features = gpd.read_file(path_to_file)\n",
    "\n",
    "    # Load cache\n",
    "    cache_file = os.path.join(path, \"data\", city, \"cache.txt\")\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            cache = set([line.strip() for line in f])\n",
    "    else:\n",
    "        cache = set()\n",
    "    \n",
    "    # Create the directory if it does not exist\n",
    "    dir_path = os.path.join(path, \"images\", city)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    dir_path = os.path.join(path, \"segments\", city)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    processor, model = get_models()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "  \n",
    "        for feature in gdf_features[\"feature\"]:\n",
    "            feature = json.loads(feature)\n",
    "            image_id = feature[\"properties\"][\"id\"]\n",
    "            \n",
    "            if image_id not in cache:\n",
    "                futures.append(executor.submit(download_image, feature, city, access_token, processor, model, path))\n",
    " \n",
    "        for future in (pbar:= tqdm(futures, total=len(futures))):\n",
    "            pbar.set_description(f\"Downloading images\")\n",
    "            image_id = future.result()\n",
    "            cache.add(image_id)\n",
    "    \n",
    "    # Save cache\n",
    "    with open(cache_file, \"w\") as f:\n",
    "        for image_id in cache:\n",
    "            f.write(\"{}\\n\".format(image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the roadnetwork of a specific city using OpenStreetMap data\n",
    "city = \"Kampala, Uganda\"\n",
    "\n",
    "# Set access token for mapillary\n",
    "access_token = \"MLY|6267906093323631|fba37c53726a386c951323ee5b9874bf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images:   0%|          | 0/49471 [00:13<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "download_images_for_points(city, access_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
