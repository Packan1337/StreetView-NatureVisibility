{"cells":[{"cell_type":"code","source":["# Use this block of code when working on Google Colab in order to save the files in Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"drive/MyDrive/Thesis/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1aujgNKvVrz","executionInfo":{"status":"ok","timestamp":1683981938632,"user_tz":-120,"elapsed":1902,"user":{"displayName":"Ilse Vázquez","userId":"07860252287419445636"}},"outputId":"ff9f24c6-be47-413d-8182-c215050c0027"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%pip install transformers\n","%pip install geopandas\n","%pip install torch==1.13.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T92Iwq3WvaG4","executionInfo":{"status":"ok","timestamp":1683981786851,"user_tz":-120,"elapsed":26188,"user":{"displayName":"Ilse Vázquez","userId":"07860252287419445636"}},"outputId":"6ecdd0bc-30bf-4b5d-f5d2-068e06cb09ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.0)\n","Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n","Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.5.0)\n","Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2022.12.7)\n","Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.3)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n","Requirement already satisfied: munch>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.22.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from munch>=2.3.2->fiona>=1.8.19->geopandas) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.5.0)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wqb2jsMQvVMK"},"outputs":[],"source":["from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n","from PIL import Image, ImageDraw\n","import torch\n","\n","import numpy as np\n","import requests\n","\n","import geopandas as gpd\n","import json\n","import os\n","\n","from concurrent.futures import ThreadPoolExecutor\n","from tqdm import tqdm\n","\n","from scipy.signal import find_peaks\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3lAX46-vVMN"},"outputs":[],"source":["# color palette to map each class to a RGB value\n","\n","color_palette = [\n","    [128, 64, 128],  # 0: road - maroon\n","    [244, 35, 232],  # 1: sidewalk - pink\n","    [70, 70, 70],  # 2: building - dark gray\n","    [102, 102, 156],  # 3: wall - purple\n","    [190, 153, 153],  # 4: fence - light brown\n","    [153, 153, 153],  # 5: pole - gray\n","    [250, 170, 30],  # 6: traffic light - orange\n","    [220, 220, 0],  # 7: traffic sign - yellow\n","    [107, 142, 35],  # 8: vegetation - dark green\n","    [152, 251, 152],  # 9: terrain - light green\n","    [70, 130, 180],  # 10: sky - blue\n","    [220, 20, 60],  # 11: person - red\n","    [255, 0, 0],  # 12: rider - bright red\n","    [0, 0, 142],  # 13: car - dark blue\n","    [0, 0, 70],  # 14: truck - navy blue\n","    [0, 60, 100],  # 15: bus - dark teal\n","    [0, 80, 100],  # 16: train - dark green\n","    [0, 0, 230],  # 17: motorcycle - blue\n","    [119, 11, 32]  # 18: bicycle - dark red\n","]"]},{"cell_type":"code","source":["def prepare_folders(city):\n","  # Create the directories to store the images, segments and pickles if they do not exist\n","  dir_path = os.path.join(path, \"results\", city, \"images\")\n","  if not os.path.exists(dir_path):\n","    os.makedirs(dir_path)\n","  \n","  dir_path = os.path.join(path, \"results\", city, \"segments\")\n","  if not os.path.exists(dir_path):\n","    os.makedirs(dir_path)\n","  \n","  dir_path = os.path.join(path, \"results\", city, \"pickles\")\n","  if not os.path.exists(dir_path):\n","    os.makedirs(dir_path)\n","\n","  dir_path = os.path.join(path, \"results\", city, \"roads\")\n","  if not os.path.exists(dir_path):\n","    os.makedirs(dir_path)"],"metadata":{"id":"WZBFlPrRPjiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"reHOXOvXvVMN"},"outputs":[],"source":["def get_models():\n","    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n","    model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n","\n","    return processor, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RN5qCDiKvVMO"},"outputs":[],"source":["def segment_images(image_path, image_id, processor, model, city, path=\"\"):\n","    image = Image.open(requests.get(image_path, stream=True).raw)\n","\n","    inputs = processor(images=image, return_tensors=\"pt\")\n","\n","    # forward pass\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    \n","    # you can pass them to processor for postprocessing\n","    seg = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n","    \n","    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n","    palette = np.array(color_palette)\n","    for label, color in enumerate(palette):\n","        color_seg[seg == label, :] = color\n","\n","    # Show image + mask\n","    img = np.array(image) * 0.4 + color_seg * 0.6\n","    img = img.astype(np.uint8)\n","\n","    # Save original image\n","    dir_path = os.path.join(path, \"results\", city, \"images\")\n","    img_path = os.path.join(dir_path, \"{}.jpg\".format(image_id))\n","    image.save(img_path)\n","    \n","    # Convert numpy array to PIL Image and save masked image\n","    pil_img = Image.fromarray(img)\n","    dir_path = os.path.join(path, \"results\", city, \"segments\")\n","    img_path = os.path.join(dir_path, \"{}.png\".format(image_id))\n","    pil_img.save(img_path)\n","\n","    # Save segmentation array as a pickle file\n","    dir_path = os.path.join(path, \"results\", city, \"pickles\")\n","    pickle_path = os.path.join(dir_path, \"{}.pkl\".format(image_id))\n","    with open(pickle_path, 'wb') as f:\n","        pickle.dump(seg, f)\n","    \n","    return pickle_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4RqT4zTvVMP"},"outputs":[],"source":["# Based on Matthew Danish code (https://github.com/mrd/vsvi_filter/tree/master)\n","def run_length_encoding(in_array):\n","    image_array = np.asarray(in_array)\n","    length = len(image_array)\n","    if length == 0: \n","        return (None, None, None)\n","    else:\n","        pairwise_unequal = image_array[1:] != image_array[:-1]\n","        change_points = np.append(np.where(pairwise_unequal), length - 1)   # must include last element posi\n","        run_lengths = np.diff(np.append(-1, change_points))       # run lengths\n","        positions = np.cumsum(np.append(0, run_lengths))[:-1] # positions\n","        return(run_lengths, positions, image_array[change_points])\n","\n","def get_road_pixels_per_column(prediction):\n","    road_pixels = prediction == 0.0 # The label for the roads is 0\n","    road_pixels_per_col = np.zeros(road_pixels.shape[1])\n","    for i in range(road_pixels.shape[1]):\n","        run_lengths, positions, values = run_length_encoding(road_pixels[:,i])\n","        road_pixels_per_col[i] = run_lengths[values.nonzero()].max(initial=0)\n","    return road_pixels_per_col\n","\n","def get_road_centres(prediction, distance=2000, prominence=100):\n","    road_pixels_per_col = get_road_pixels_per_column(prediction)\n","    return find_peaks(road_pixels_per_col, distance=distance, prominence=prominence)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hwhQRWsYvVMQ"},"outputs":[],"source":["def find_road_center(filename):\n","    predict = np.load(filename, allow_pickle=True)\n","\n","    distance = int(2000 * predict.shape[1] // 5760)\n","    prominence = int(100 * predict.shape[0] // 2880)\n","\n","    centres = get_road_centres(predict, distance=distance, prominence=prominence)\n","    \n","    if centres.size > 0:\n","      palette_bytes = bytes([c for color in color_palette for c in color]) # concatenate rgb\n","      predict_np = predict.numpy()\n","      mask = Image.fromarray(predict_np.astype('uint8')).convert('P')\n","      mask.putpalette(palette_bytes)\n","      mask.load()\n","      \n","      draw = ImageDraw.Draw(mask)\n","      \n","      for centre in centres:\n","        draw.line((centre, 0, centre, mask.size[1]), width=4, fill=(0,255,0))\n","    \n","      path_to_file=\"{}results/{}/roads/points_with_features.gpkg\".format(path, city, city)\n","      mask.save(\"test.png\")\n","\n","      return True\n","    else:\n","      return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqe9dQ1XvVMO"},"outputs":[],"source":["# Download images\n","def download_image(image_metadata, city, access_token, processor, model, path=\"\"):\n","    header = {'Authorization': 'OAuth {}'.format(access_token)}\n","\n","    image_id = image_metadata[\"properties\"][\"id\"]\n","    \n","    url = 'https://graph.mapillary.com/{}?fields=thumb_original_url'.format(image_id)\n","    response = requests.get(url, headers=header)\n","    data = response.json()\n","    image_url = data[\"thumb_original_url\"]\n","\n","    # Image segmentation\n","    pickle_path = segment_images(image_url, image_id, processor, model, city)\n","    \n","    # Find roads to determine if the image is suitable for the analysis or not AND crop the panoramic images\n","    find_road_center(pickle_path)\n","\n","    return image_id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yi70VyJLvVMP"},"outputs":[],"source":["def download_images_for_points(city, access_token, path=\"\"):\n","    path_to_file=\"{}results/{}/data/points_with_features.gpkg\".format(path, city, city)\n","    gdf_features = gpd.read_file(path_to_file)\n","\n","    # Load cache\n","    cache_file = os.path.join(path, \"results\", city, \"data\", \"cache.txt\")\n","    if os.path.exists(cache_file):\n","        with open(cache_file, \"r\") as f:\n","            cache = set([line.strip() for line in f])\n","    else:\n","        cache = set()\n","\n","    prepare_folders(city)\n","    processor, model = get_models()\n","\n","    with ThreadPoolExecutor(max_workers=10) as executor:\n","        futures = []\n","  \n","        for feature in gdf_features[\"feature\"]:\n","            feature = json.loads(feature)\n","            image_id = feature[\"properties\"][\"id\"]\n","            \n","            if image_id not in cache:\n","                futures.append(executor.submit(download_image, feature, city, access_token, processor, model, path))\n"," \n","        for future in (pbar:= tqdm(futures, total=len(futures))):\n","            pbar.set_description(f\"Downloading images\")\n","            image_id = future.result()\n","            cache.add(image_id)\n","    \n","    # Save cache\n","    with open(cache_file, \"w\") as f:\n","        for image_id in cache:\n","            f.write(\"{}\\n\".format(image_id))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hV_HAPW1vVMQ"},"outputs":[],"source":["# Get the roadnetwork of a specific city using OpenStreetMap data\n","city = \"Kampala, Uganda\"\n","\n","# Set access token for mapillary\n","access_token = \"MLY|6267906093323631|fba37c53726a386c951323ee5b9874bf\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFEx3Hp0vVMQ"},"outputs":[],"source":["download_images_for_points(city, access_token)"]}],"metadata":{"kernelspec":{"display_name":"ssml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}