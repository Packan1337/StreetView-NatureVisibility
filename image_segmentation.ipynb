{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1aujgNKvVrz",
        "outputId": "f97f058b-3269-47a5-9ff1-fbfe4418bdf1"
      },
      "outputs": [],
      "source": [
        "# Use this block of code when working on Google Colab in order to save the files in Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#path = \"drive/MyDrive/Thesis/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T92Iwq3WvaG4",
        "outputId": "5d1df63c-32d7-4993-f984-126418e3cc90"
      },
      "outputs": [],
      "source": [
        "#%pip install transformers\n",
        "#%pip install geopandas\n",
        "#%pip install torch==1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Wqb2jsMQvVMK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f_/xfklpqfj6kjg8yr6l1byph0h0000gn/T/ipykernel_2207/2476603906.py:8: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
            "\n",
            "import os\n",
            "os.environ['USE_PYGEOS'] = '0'\n",
            "import geopandas\n",
            "\n",
            "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
            "  import geopandas as gpd\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "import geopandas as gpd\n",
        "import json\n",
        "import os\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# color palette to map each class to a RGB value\n",
        "color_palette = [\n",
        "    [128, 64, 128],  # 0: road - maroon\n",
        "    [244, 35, 232],  # 1: sidewalk - pink\n",
        "    [70, 70, 70],  # 2: building - dark gray\n",
        "    [102, 102, 156],  # 3: wall - purple\n",
        "    [190, 153, 153],  # 4: fence - light brown\n",
        "    [153, 153, 153],  # 5: pole - gray\n",
        "    [250, 170, 30],  # 6: traffic light - orange\n",
        "    [220, 220, 0],  # 7: traffic sign - yellow\n",
        "    [107, 142, 35],  # 8: vegetation - dark green\n",
        "    [152, 251, 152],  # 9: terrain - light green\n",
        "    [70, 130, 180],  # 10: sky - blue\n",
        "    [220, 20, 60],  # 11: person - red\n",
        "    [255, 0, 0],  # 12: rider - bright red\n",
        "    [0, 0, 142],  # 13: car - dark blue\n",
        "    [0, 0, 70],  # 14: truck - navy blue\n",
        "    [0, 60, 100],  # 15: bus - dark teal\n",
        "    [0, 80, 100],  # 16: train - dark green\n",
        "    [0, 0, 230],  # 17: motorcycle - blue\n",
        "    [119, 11, 32]  # 18: bicycle - dark red\n",
        "]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The following functions were made just to visualise the results of some parts of the code and make sure that it was correctly working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_results(image, segmentation):\n",
        "    _, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Display the widened panorama image\n",
        "    ax[0].imshow(image)\n",
        "    ax[0].set_title(\"Widened Panorama Image\")\n",
        "    ax[0].axis(\"off\")\n",
        "\n",
        "    # Display the segmentation result\n",
        "    ax[1].imshow(segmentation, cmap='jet', interpolation='nearest')\n",
        "    ax[1].set_title(\"Segmentation Result\")\n",
        "    ax[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_road_centres(segmentation, centres):\n",
        "    palette_bytes = bytes([c for color in color_palette for c in color]) # concatenate rgb\n",
        "    predict_np = segmentation.numpy()\n",
        "    mask = Image.fromarray(predict_np.astype('uint8')).convert('P')\n",
        "    mask.putpalette(palette_bytes)\n",
        "    mask.load()\n",
        "      \n",
        "    draw = ImageDraw.Draw(mask)\n",
        "      \n",
        "    for centre in centres:\n",
        "        draw.line((centre, 0, centre, mask.size[1]), width=4, fill=(0,255,0))\n",
        "    \n",
        "    mask.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WZBFlPrRPjiT"
      },
      "outputs": [],
      "source": [
        "def prepare_folders(path, city):\n",
        "\tdir_path = os.path.join(path, \"results\", city, \"images\")\n",
        "\tif not os.path.exists(dir_path):\n",
        "\t\tos.makedirs(dir_path)\n",
        "\t\n",
        "\tdir_path = os.path.join(path, \"results\", city, \"final_images\")\n",
        "\tif not os.path.exists(dir_path):\n",
        "\t\tos.makedirs(dir_path)\n",
        "\t\n",
        "\tdir_path = os.path.join(path, \"results\", city, \"segments\")\n",
        "\tif not os.path.exists(dir_path):\n",
        "\t\tos.makedirs(dir_path)\n",
        "\t\n",
        "\tdir_path = os.path.join(path, \"results\", city, \"pickles\")\n",
        "\tif not os.path.exists(dir_path):\n",
        "\t\tos.makedirs(dir_path)\n",
        "\n",
        "\tdir_path = os.path.join(path, \"results\", city, \"final_pickles\")\n",
        "\tif not os.path.exists(dir_path):\n",
        "\t\tos.makedirs(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "reHOXOvXvVMN"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
        "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
        "    return processor, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RN5qCDiKvVMO"
      },
      "outputs": [],
      "source": [
        "def segment_images(image, processor, model):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    \n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    # You can pass them to processor for postprocessing\n",
        "    segmentation = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
        "\n",
        "    return segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_files(image_id, image, segmentation, images, pickles, city, path=\"\"):\n",
        "    # Save original image \n",
        "    dir_path = os.path.join(path, \"results\", city, \"images\")\n",
        "    img_path = os.path.join(dir_path, \"{}.jpg\".format(image_id))\n",
        "    image.save(img_path)\n",
        "\n",
        "    color_seg = np.zeros((segmentation.shape[0], segmentation.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
        "    palette = np.array(color_palette)\n",
        "    for label, color in enumerate(palette):\n",
        "        color_seg[segmentation == label, :] = color\n",
        "    \n",
        "    # Show image + mask\n",
        "    img = np.array(image) * 0.4 + color_seg * 0.6\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    # Save final images\n",
        "    dir_path = os.path.join(path, \"results\", city, \"final_images\")\n",
        "    for index, image in enumerate(images):\n",
        "        img_path = os.path.join(dir_path, \"{}_{}.jpg\".format(image_id, index))\n",
        "        image.save(img_path)\n",
        "    \n",
        "    # Convert numpy array to PIL Image and save masked image\n",
        "    pil_img = Image.fromarray(img)\n",
        "    dir_path = os.path.join(path, \"results\", city, \"segments\")\n",
        "    img_path = os.path.join(dir_path, \"{}.png\".format(image_id))\n",
        "    pil_img.save(img_path)\n",
        "\n",
        "    # Save segmentation array as a pickle file\n",
        "    dir_path = os.path.join(path, \"results\", city, \"pickles\")\n",
        "    pickle_path = os.path.join(dir_path, \"{}.pkl\".format(image_id))\n",
        "    with open(pickle_path, 'wb') as f:\n",
        "        pickle.dump(segmentation, f)\n",
        "    \n",
        "    # Save final segmentation arrays as a pickle file\n",
        "    dir_path = os.path.join(path, \"results\", city, \"final_pickles\")\n",
        "    for index, pick in enumerate(pickles):\n",
        "        pickle_path = os.path.join(dir_path, \"{}_{}.pkl\".format(image_id, index))\n",
        "        with open(pickle_path, 'wb') as f:\n",
        "            pickle.dump(pick, f)\n",
        "    \n",
        "    return pickle_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D4RqT4zTvVMP"
      },
      "outputs": [],
      "source": [
        "# Based on Matthew Danish code (https://github.com/mrd/vsvi_filter/tree/master)\n",
        "def run_length_encoding(in_array):\n",
        "    image_array = np.asarray(in_array)\n",
        "    length = len(image_array)\n",
        "    if length == 0: \n",
        "        return (None, None, None)\n",
        "    else:\n",
        "        pairwise_unequal = image_array[1:] != image_array[:-1]\n",
        "        change_points = np.append(np.where(pairwise_unequal), length - 1)   # must include last element posi\n",
        "        run_lengths = np.diff(np.append(-1, change_points))       # run lengths\n",
        "        return(run_lengths, image_array[change_points])\n",
        "\n",
        "def get_road_pixels_per_column(prediction):\n",
        "    road_pixels = prediction == 0.0 # The label for the roads is 0\n",
        "    road_pixels_per_col = np.zeros(road_pixels.shape[1])\n",
        "    \n",
        "    for i in range(road_pixels.shape[1]):\n",
        "        run_lengths, values = run_length_encoding(road_pixels[:,i])\n",
        "        road_pixels_per_col[i] = run_lengths[values.nonzero()].max(initial=0)\n",
        "    return road_pixels_per_col\n",
        "\n",
        "def get_road_centres(prediction, distance=2000, prominence=100):\n",
        "    road_pixels_per_col = get_road_pixels_per_column(prediction)\n",
        "    peaks, _ = find_peaks(road_pixels_per_col, distance=distance, prominence=prominence)\n",
        "    \n",
        "    return peaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_road_centre(segmentation):\n",
        "\tdistance = int(2000 * segmentation.shape[1] // 5760)\n",
        "\tprominence = int(100 * segmentation.shape[0] // 2880)\n",
        "\t\n",
        "\tcentres = get_road_centres(segmentation, distance=distance, prominence=prominence)\n",
        "\t\n",
        "\treturn centres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop_panoramic_images(original_width, image, segmentation, road_centre):\n",
        "    width, height = image.size\n",
        "\n",
        "    # Find duplicated centres\n",
        "    duplicated_centres = [centre - original_width for centre in road_centre if centre >= original_width]\n",
        "            \n",
        "    # Drop the duplicated centres\n",
        "    road_centre = [centre for centre in road_centre if centre not in duplicated_centres]\n",
        "\n",
        "    # Calculate dimensions and offsets\n",
        "    w4 = int(width / 4) # \n",
        "    h4 = int(height / 4)\n",
        "    hFor43 = int(w4 * 3 / 4)\n",
        "    w98 = width + (w4 / 2)\n",
        "    xrapneeded = int(width * 7 / 8)\n",
        "\n",
        "    images = []\n",
        "    pickles = []\n",
        "    # Crop the panoramic image\n",
        "    for centre in road_centre:\n",
        "        # Wrapped all the way around\n",
        "        if centre >= w98:\n",
        "            xlo = int(centre - w4/2)\n",
        "            cropped_image = image.crop((xlo, h4,  xlo+w4, h4 + hFor43))\n",
        "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
        "        \n",
        "        # Image requires assembly of two sides\n",
        "        elif centre > xrapneeded:\n",
        "            xlo = int(centre - w4 / 2) # horizontal_offset\n",
        "            w4_p1 = width - xlo\n",
        "            w4_p2 = w4 - w4_p1\n",
        "            cropped_image_1 = image.crop((xlo, h4, xlo + w4_p1, h4 + hFor43))\n",
        "            cropped_image_2 = image.crop((0, h4, w4_p2, h4 + hFor43))\n",
        "\n",
        "            cropped_image = Image.new(image.mode, (w4, hFor43))\n",
        "            cropped_image.paste(cropped_image_1, (0, 0))\n",
        "            cropped_image.paste(cropped_image_2, (w4_p1, 0))\n",
        "\n",
        "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
        "        \n",
        "        # Must paste together the two sides of the image\n",
        "        elif centre < (w4 / 2):\n",
        "            w4_p1 = int((w4 / 2) - width)\n",
        "            xhi = height - w4_p1\n",
        "            w4_p2 = w4 - w4_p1\n",
        "\n",
        "            cropped_image_1 = image.crop((xhi, h4, xhi + w4_p1, h4 + hFor43))\n",
        "            cropped_image_2 = image.crop((0, h4, w4_p2, h4 + hFor43))\n",
        "\n",
        "        # Straightforward crop\n",
        "        else:\n",
        "            xlo = int(centre - w4/2)\n",
        "            cropped_image = image.crop((xlo, h4, xlo + w4, h4 + hFor43))\n",
        "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
        "        \n",
        "        images.append(cropped_image)\n",
        "        pickles.append(cropped_segmentation)\n",
        "        \n",
        "        visualize_results(cropped_image, cropped_segmentation)\n",
        "\n",
        "    return images, pickles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_GVI(segmentations):\n",
        "    green_percentage = 0\n",
        "    for segment in segmentations:\n",
        "        total_pixels = segment.numel()\n",
        "        vegetation_pixels = (segment == 8).sum().item()\n",
        "        green_percentage += vegetation_pixels / total_pixels\n",
        "    \n",
        "    return green_percentage / len(segmentations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_images(image_id, image_url, is_panoramic, processor, model, city, path):\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "    if is_panoramic:\n",
        "        # Get the size of the image\n",
        "        width, height = image.size\n",
        "\n",
        "        # Crop the bottom 20% of the image to cut the band on the bottom of the panoramic image\n",
        "        bottom_crop = int(height * 0.2)\n",
        "        image = image.crop((0, 0, width, height - bottom_crop))\n",
        "\n",
        "    # Image segmentation\n",
        "    segmentation = segment_images(image, processor, model)\n",
        "\n",
        "    if is_panoramic:\n",
        "        # Create a widened panorama by wrapping the first 25% of the image onto the right edge\n",
        "        width, height = image.size\n",
        "        w4 = int(0.25 * width)\n",
        "\n",
        "        segmentation_25 = segmentation[:, :w4]\n",
        "        # Concatenate the tensors along the first dimension (rows)\n",
        "        segmentation_road = torch.cat((segmentation, segmentation_25), dim=1)\n",
        "    else:\n",
        "        segmentation_road = segmentation\n",
        "        \n",
        "    # Find roads to determine if the image is suitable for the analysis or not AND crop the panoramic images\n",
        "    road_centre = find_road_centre(segmentation_road)\n",
        "\n",
        "    if len(road_centre) > 0:\n",
        "        if is_panoramic:\n",
        "            images, pickles = crop_panoramic_images(width, image, segmentation_road, road_centre)\n",
        "        else:\n",
        "            images = [image]\n",
        "            pickles = [segmentation]\n",
        "        \n",
        "        # Now we can get the Green View Index\n",
        "        GVI = get_GVI(pickles)\n",
        "    \n",
        "        save_files(image_id, image, segmentation, images, pickles, city, path)\n",
        "        return [GVI, is_panoramic, False]\n",
        "    else:\n",
        "        # There are not road centres, so the image is unusable\n",
        "        return [0, None, True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vqe9dQ1XvVMO"
      },
      "outputs": [],
      "source": [
        "# Download images\n",
        "def download_image(index, geometry, image_metadata, city, access_token, processor, model, path=\"\"):\n",
        "    prepare_folders(path, city)\n",
        "    header = {'Authorization': 'OAuth {}'.format(access_token)}\n",
        "\n",
        "    image_id = image_metadata[\"properties\"][\"id\"]\n",
        "    is_panoramic = image_metadata[\"properties\"][\"is_pano\"]\n",
        "    \n",
        "    url = 'https://graph.mapillary.com/{}?fields=thumb_original_url'.format(image_id)\n",
        "    response = requests.get(url, headers=header)\n",
        "    data = response.json()\n",
        "    image_url = data[\"thumb_original_url\"]\n",
        "\n",
        "    result = process_images(image_id, image_url, is_panoramic, processor, model, city, path)\n",
        "    result.insert(0, geometry)\n",
        "    result.insert(0, index)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Yi70VyJLvVMP"
      },
      "outputs": [],
      "source": [
        "def download_images_for_points(gdf, city, access_token, path=\"\"):\n",
        "    processor, model = get_models()\n",
        "    prepare_folders(path, city)\n",
        "    \n",
        "    images_results = []\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "  \n",
        "        for index, row in gdf.iterrows():\n",
        "            feature = row[\"feature\"]\n",
        "            geometry = row[\"geometry\"]\n",
        "            feature = json.loads(feature)\n",
        "            futures.append(executor.submit(download_image, index, geometry, feature, city, access_token, processor, model, path))\n",
        " \n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading images\"):\n",
        "            image_result = future.result()\n",
        "            images_results.append(image_result)\n",
        "\n",
        "    return gpd.GeoDataFrame(images_results, columns=[\"original_index\", \"geometry\", \"GVI\", \"is_panoramic\", \"missing\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hV_HAPW1vVMQ"
      },
      "outputs": [],
      "source": [
        "# Get the roadnetwork of a specific city using OpenStreetMap data\n",
        "city = \"Kampala, Uganda\"\n",
        "\n",
        "# Set access token for mapillary\n",
        "access_token = \"MLY|6267906093323631|fba37c53726a386c951323ee5b9874bf\"\n",
        "path = \"\"\n",
        "\n",
        "path_to_file=\"{}results/{}/data/points_with_features.gpkg\".format(path, city)\n",
        "gdf_features = gpd.read_file(path_to_file)\n",
        "\n",
        "gdf_features = gdf_features.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFEx3Hp0vVMQ",
        "outputId": "e1589c07-7ce7-4217-c539-63922169f1a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading images: 100%|██████████| 10/10 [00:30<00:00,  3.04s/it]\n"
          ]
        }
      ],
      "source": [
        "results = download_images_for_points(gdf_features, city, access_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>geometry</th>\n",
              "      <th>GVI</th>\n",
              "      <th>is_panoramic</th>\n",
              "      <th>missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>POINT (32.59872 0.33859)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>POINT (32.59706 0.33938)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>POINT (32.59969 0.33767)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>POINT (32.59793 0.33903)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>POINT (32.59995 0.33730)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7</td>\n",
              "      <td>POINT (32.59941 0.33802)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>POINT (32.59714 0.33946)</td>\n",
              "      <td>0.336839</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>POINT (32.59832 0.33881)</td>\n",
              "      <td>0.186828</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>POINT (32.59753 0.33924)</td>\n",
              "      <td>0.232132</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6</td>\n",
              "      <td>POINT (32.59908 0.33833)</td>\n",
              "      <td>0.206590</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                  geometry       GVI is_panoramic  missing\n",
              "0      5  POINT (32.59872 0.33859)  0.000000         None     True\n",
              "1      0  POINT (32.59706 0.33938)  0.000000         None     True\n",
              "2      8  POINT (32.59969 0.33767)  0.000000         None     True\n",
              "3      3  POINT (32.59793 0.33903)  0.000000         None     True\n",
              "4      9  POINT (32.59995 0.33730)  0.000000         None     True\n",
              "5      7  POINT (32.59941 0.33802)  0.000000         None     True\n",
              "6      1  POINT (32.59714 0.33946)  0.336839        False    False\n",
              "7      4  POINT (32.59832 0.33881)  0.186828        False    False\n",
              "8      2  POINT (32.59753 0.33924)  0.232132        False    False\n",
              "9      6  POINT (32.59908 0.33833)  0.206590        False    False"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ssml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
